{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MUbA6SnaK3-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64WG8T5mJ2PP",
        "outputId": "153d4fd9-4376-4a8b-d7e4-756664c6162d"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data/CAP Dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fspfDj5vdeK4",
        "outputId": "863f94f7-8a4b-4561-fd4d-44fbbf642080"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/data/Copy of images_normalized.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9axgYTPcXau",
        "outputId": "3ca65aaa-5e3a-4069-a76f-1c624606a389"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "print(len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkxGS_xDcl-R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import Sequential\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAB2P9vAd8yD"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/dataset/train/'\n",
        "test_dir = '/content/dataset/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VxziLeZcoVo",
        "outputId": "a2ac42cd-786b-41d5-8d11-66f5a91f6fb2"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale = 1/255. ,\n",
        "                              validation_split=0.2,\n",
        "                             )\n",
        "datagen2 = ImageDataGenerator(rescale = 1/255.\n",
        "                              )\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "valid_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    subset = 'validation'\n",
        "\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDli2w1bdIIO"
      },
      "outputs": [],
      "source": [
        "# train_data2 = tf.data.Dataset.from_generator(\n",
        "#     lambda: train_data,\n",
        "#     output_signature=(\n",
        "#         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "#         tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "#     )\n",
        "# )\n",
        "# valid_data2 = tf.data.Dataset.from_generator(\n",
        "#     lambda: valid_data,\n",
        "#     output_signature=(\n",
        "#         tf.TensorSpec(shape=(None,224, 224, 3), dtype=tf.float32),\n",
        "#         tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "#     )\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsgTIckjdJ1m",
        "outputId": "9b84c70a-c91a-441f-8e50-2cd20cb3409e"
      },
      "outputs": [],
      "source": [
        "test_data = datagen2.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary',\n",
        "    color_mode='rgb'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omqgoZ3tdO_g"
      },
      "outputs": [],
      "source": [
        "# input_layer = tf.keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# x = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(input_layer)\n",
        "# x = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "# x = tf.keras.layers.SeparableConv2D(32, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.SeparableConv2D(32, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "# x = tf.keras.layers.SeparableConv2D(64, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.SeparableConv2D(64, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "# x = tf.keras.layers.SeparableConv2D(128, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.SeparableConv2D(128, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.MaxPool2D()(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "# x = tf.keras.layers.SeparableConv2D(256, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.SeparableConv2D(256, 3, activation='relu', padding='same')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.MaxPool2D()(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "# x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.Dropout(0.7)(x)\n",
        "\n",
        "# x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "# output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "PaXYoSIEe8eB",
        "outputId": "21592612-494a-4c81-a8c9-14b52b7baf11"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UUa0IfumbGI"
      },
      "outputs": [],
      "source": [
        "# len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p6_ipsifIpn"
      },
      "outputs": [],
      "source": [
        "# history1 = model.fit(\n",
        "#     train_data2,\n",
        "#     steps_per_epoch = len(train_data),\n",
        "#     validation_data = valid_data2,\n",
        "#     validation_steps = int(0.25* len(valid_data)),\n",
        "#     epochs=50\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using VGG model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxKpk4iNlvDB",
        "outputId": "e0a3862b-d4ba-4fd0-f4bd-ffbd9fb59ace"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "METRICS = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "vggmodel = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "vggmodel.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5asQQZ1FBdFl",
        "outputId": "663642cd-d0c2-4f13-87e3-dfea27ec0efc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(lr = 1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AKwixqMrYGC"
      },
      "outputs": [],
      "source": [
        "vggmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics= ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1bJMax4q89E"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "mNdqd-Wjfg4E",
        "outputId": "59d372dc-c0ae-4cca-db3c-4ca5ef4a16fd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "ckpt = ModelCheckpoint('./best.h5',\n",
        "                       monitor= \"val_loss\",\n",
        "                       save_best_only=True\n",
        "\n",
        "                      )\n",
        "\n",
        "history_1 = vggmodel.fit(\n",
        "    train_data2,\n",
        "    steps_per_epoch = len(train_data),\n",
        "    validation_data = valid_data2,\n",
        "    validation_steps = int(0.25* len(valid_data)),\n",
        "    epochs=50,\n",
        "    callbacks = [early_stopping_cb ]\n",
        ")\n",
        "\n",
        "vggmodel.save('./modelvgg_epoch.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KFG-f1bD5Nu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJtAJ20sD7Tw"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWUe9zA4wudy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtoCXCzDrHfC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXavcs3z6lBc"
      },
      "source": [
        "## Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-3uUS2d6nSE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNRldvu1PYvp"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/dataset/train/'\n",
        "test_dir = '/content/dataset/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVhfNJTYPXwu",
        "outputId": "9f92f8e1-765d-4d2a-d048-c00acb4a6bd3"
      },
      "outputs": [],
      "source": [
        "train_data = keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=62,\n",
        "    label_mode=\"binary\",\n",
        ")\n",
        "\n",
        "test_data = keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=64 ,\n",
        "    label_mode=\"binary\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX-KOGVUC1kS",
        "outputId": "0a644320-ef87-495f-e135-2984c41364b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torchvision\n",
        "pretrained_resnet_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n",
        "\n",
        "pretrained_resnet = tf.keras.applications.resnet50.ResNet50(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),  # Adjust input shape to your dataset\n",
        "    include_top=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "k5RZYXL2C8zL",
        "outputId": "9c820a22-42f9-487a-dbf5-588aa692042f"
      },
      "outputs": [],
      "source": [
        "for layer in pretrained_.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "class_names = ['A', 'not_A']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixzJHbRENjHs"
      },
      "outputs": [],
      "source": [
        "pretrained_vit.output.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh1GBDpcDF3G",
        "outputId": "1690657d-ea52-49d1-8cfe-84bc358f85a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "EJqvBbXADJen",
        "outputId": "4398fcab-7d81-4a71-be99-444251485f35"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Define data preprocessing and augmentation\n",
        "random = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(scale=1./255),\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.Resizing(224, 224),\n",
        "])\n",
        "\n",
        "# Load a pretrained ResNet model (you can use any pretrained model)\n",
        "pretrained_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the pretrained ResNet model\n",
        "for layer in pretrained_resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create your custom head for the model\n",
        "x = Flatten()(pretrained_resnet.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Combine the random preprocessing and your custom head\n",
        "resnetmodel = Model(inputs=random.input, outputs=output)\n",
        "\n",
        "# Print a summary of the model\n",
        "resnetmodel.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "qQ5rCdJBDVcF",
        "outputId": "24d8b5ac-c337-4ebb-b783-3834aec8b247"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(lr = 1e-4)\n",
        "resnetmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 30\n",
        "\n",
        "history = resnetmodel.fit(\n",
        "    train_data,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=test_data,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq_YCpg2QQmM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgbz3P3cUbbj"
      },
      "source": [
        "# Using VIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BrkQtz7UbV_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMkJj6FMUdRX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7V2JHrCU6Og",
        "outputId": "3bbd214e-d306-4e1c-f8c8-7a7096f246ec"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data/CAP Dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2b2IC3mU8L1"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/dataset/train/'\n",
        "test_dir = '/content/dataset/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "xvYW4ZfqVuE3",
        "outputId": "2677441a-7dc6-4680-c27c-6648fb41c43d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/data/train/A/cwtm_image_1.png\"\n",
        "image = tf.image.decode_image(tf.io.read_file(image_path))\n",
        "\n",
        "# Get the shape of the image\n",
        "shape = tf.shape(image)\n",
        "\n",
        "# Extract the dimensions (shape)\n",
        "height = shape[0]\n",
        "width = shape[1]\n",
        "channels = shape[2]\n",
        "\n",
        "# Print the dimensions\n",
        "print(f\"Image width: {width} pixels\")\n",
        "print(f\"Image height: {height} pixels\")\n",
        "print(f\"Number of channels: {channels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "YCgFW2xXVXfi",
        "outputId": "d6ec91f6-41dd-4ccf-fb5d-0af21106be7a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the image\n",
        "image_path = \"your_image.jpg\"\n",
        "image = tf.image.decode_image(tf.io.read_file(image_path))\n",
        "\n",
        "# Get the shape of the image\n",
        "shape = tf.shape(image)\n",
        "\n",
        "# Extract the dimensions (shape)\n",
        "height = shape[0]\n",
        "width = shape[1]\n",
        "channels = shape[2]\n",
        "\n",
        "# Print the dimensions\n",
        "print(f\"Image width: {width} pixels\")\n",
        "print(f\"Image height: {height} pixels\")\n",
        "print(f\"Number of channels: {channels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP4ezl4yUhBJ",
        "outputId": "93fe1d5c-4630-443e-fdf3-0f22964933b2"
      },
      "outputs": [],
      "source": [
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode = 'binary',\n",
        "    image_size=(224,224) ,\n",
        "    batch_size =32,\n",
        "    color_mode = 'rgb'\n",
        ")\n",
        "\n",
        "\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    label_mode = 'binary',\n",
        "    image_size=(224,224) ,\n",
        "    batch_size =32,\n",
        "    color_mode = 'rgb'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVFBDMVtWOft",
        "outputId": "bfd28c14-9bbb-4ac2-8a34-c5ec7eb8a04f"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YiXnrWdWWNi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu10ByoiWwl0"
      },
      "outputs": [],
      "source": [
        "transform = keras.Sequential([\n",
        "    layers.Rescaling(scale=1./255),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.Resizing(224, 224),\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtu1jHzoWtkv"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    preprocessing.RandomFlip(),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2)\n",
        "    # preprocessing.Rescale(1/255.),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbFC0h4TYgYp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdT9SZCQYj98",
        "outputId": "194bf66e-ed0e-456c-a8ce-4ae56908c291"
      },
      "outputs": [],
      "source": [
        "input_shape = (224,224,3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable  = False\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape = input_shape)\n",
        "\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x , training = False)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "outputs = layers.Dense(1 , activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "\n",
        "model_1 = keras.Model(inputs , outputs)\n",
        "\n",
        "model_1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-tZXR1p3-o4"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "# https://tfhub.dev/sayakpaul/vit_s16_classification/1\n",
        "\n",
        "\n",
        "\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "\n",
        "\n",
        "base_model = hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_s16_classification/1\" , trainable = False , input_shape = input_shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOH9YZOl6ewi"
      },
      "outputs": [],
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.Dense(1 , activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57T7MdvjaYoL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "path = '/content/'\n",
        "model_ckpt= tf.keras.callbacks.ModelCheckpoint(filepath = path,\n",
        "                                               save_weight_only = True,\n",
        "                                               save_best_only = False,\n",
        "                                               save_freq = 'epoch',\n",
        "                                               verbose=1\n",
        "                                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSUoiNTkZdDj",
        "outputId": "a6581403-1908-446c-9869-eaa9f3aa1a8a"
      },
      "outputs": [],
      "source": [
        "model_1.compile(loss = 'binary_crossentropy', optimizer= tf.keras.optimizers.Adam(lr=1e-4) ,metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "history_1 = model_1.fit(train_data ,\n",
        "                        epochs  = 30,\n",
        "                        steps_per_epoch= len(train_data),\n",
        "                        validation_data = test_data,\n",
        "                        validation_steps = int(0.15*len(test_data)),\n",
        "                        callbacks = [early_stopping_cb , model_ckpt]\n",
        "\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdhOVn4taggZ",
        "outputId": "b66f0884-4778-45a7-86ce-640ee9fd3983"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HrYbTUKuHCC",
        "outputId": "7ed111bb-900f-46e1-abc2-60ef72f00e3f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (224, 224, 3)  # You can adjust the input shape to match your dataset\n",
        "\n",
        "# Load the ViT-B/16 model from TensorFlow Hub\n",
        "model_url = \"https://tfhub.dev/sayakpaul/vit_b16_classification/1\"\n",
        "vit_model = hub.load(model_url)\n",
        "\n",
        "# Create a custom Keras layer for the ViT model\n",
        "class VitLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(VitLayer, self).__init__()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return vit_model(inputs)\n",
        "\n",
        "# Create a new model with a custom output layer for your specific task\n",
        "inputs = Input(shape=input_shape)\n",
        "vit_output = VitLayer()(inputs)\n",
        "# Add a spatial dimension for GlobalAveragePooling2D\n",
        "vit_output = tf.expand_dims(vit_output, axis=1)\n",
        "vit_output = tf.expand_dims(vit_output, axis=1)\n",
        "vit_layer = tf.keras.layers.GlobalAveragePooling2D()(vit_output)\n",
        "output = Dense(1, activation='sigmoid')(vit_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcUXrrrkuYY1",
        "outputId": "b88754c0-7d09-4a3f-8db6-9175415bbea0"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_data ,\n",
        "                        epochs  = 30,\n",
        "                        steps_per_epoch= len(train_data),\n",
        "                        validation_data = test_data,\n",
        "                        validation_steps = int(0.15*len(test_data)),\n",
        "                        # callbacks = [ model_ckpt]\n",
        "\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "lyUHKSnBe_pD",
        "outputId": "9a389219-43bc-4d82-efc8-369f5dc98140"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "input_shape = (224, 224, 3)  \n",
        "\n",
        "model_url = \"https://tfhub.dev/sayakpaul/vit_b16_classification/1\"\n",
        "vit_model = hub.load(model_url)\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "vit_output = vit_model(inputs)\n",
        "output = Dense(1, activation='sigmoid')(vit_output)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',  # Use the appropriate loss function for your task\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBl-fJ5HcmVN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "\n",
        "path = '/content/'\n",
        "model_ckpt= tf.keras.callbacks.ModelCheckpoint(filepath = path,\n",
        "                                               save_weight_only = True,\n",
        "                                               save_best_only = False,\n",
        "                                               save_freq = 'epoch',\n",
        "                                               verbose=1\n",
        "                                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSqq_zWJdPNS"
      },
      "outputs": [],
      "source": [
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch % 10 == 0 and epoch > 0:\n",
        "        return lr * 0.5\n",
        "    return lr\n",
        "\n",
        "learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_scheduler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n_mHcgqc_wB",
        "outputId": "f33ffe76-478f-4cb5-8f42-82b96464268d"
      },
      "outputs": [],
      "source": [
        "model_2.compile(loss = 'binary_crossentropy', optimizer= keras.optimizers.Adam(lr=1e-4) ,metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "history_2 = model_2.fit(train_data ,\n",
        "                        epochs  = 30,\n",
        "                        steps_per_epoch= len(train_data),\n",
        "                        validation_data = test_data,\n",
        "                        validation_steps = int(0.15*len(test_data)),\n",
        "                        callbacks = [early_stopping_cb , model_ckpt , learning_rate_scheduler]\n",
        "\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KTtfpgwEACX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0usq8ojSdpcs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define your data augmentation layer\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "# You can then apply this layer to your input data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "XUMcKu-PCyGU",
        "outputId": "d446e8ea-0476-471f-dc22-0eda3e6dcc34"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load a pre-trained EfficientNet model\n",
        "model_url = \"https://tfhub.dev/google/efficientnet/b3/classification/1\"\n",
        "efficientnet = hub.load(model_url)\n",
        "\n",
        "# Modify the model for binary classification\n",
        "model = keras.Sequential([\n",
        "    efficientnet,\n",
        "    layers.GlobalAveragePooling2D(),  # Global Average Pooling layer\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jibbBK7IDBYO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load a pre-trained EfficientNet model\n",
        "model_url = \"https://tfhub.dev/google/efficientnet/b3/classification/1\"\n",
        "efficientnet = hub.load(model_url)\n",
        "\n",
        "# Define your data augmentation settings\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Load your image datasets\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode='binary',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    label_mode='binary',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "# Create your model\n",
        "model = keras.Sequential([\n",
        "    efficientnet,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Apply data augmentation using the ImageDataGenerator\n",
        "train_data = train_data.map(lambda x, y: (datagen.random_transform(x), y))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, validation_data=test_data, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a3SWRu6Ec8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK1-JzaDjimC"
      },
      "source": [
        "# Using GASF images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzpRJQcPx427",
        "outputId": "603b7a95-8ffb-44b7-c8ff-eec85f47669c"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data/data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM4ztsOrjkMV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "train_dir = '/content/data/train'\n",
        "test_dir = '/content/data/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCbyRS_Punts"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Load the image\n",
        "# image_path = \"/content/data/train/A/cwtm_image_1.png\"\n",
        "# image = tf.image.decode_image(tf.io.read_file(image_path))\n",
        "\n",
        "# # Get the shape of the image\n",
        "# shape = tf.shape(image)\n",
        "\n",
        "# # Extract the dimensions (shape)\n",
        "# height = shape[0]\n",
        "# width = shape[1]\n",
        "# channels = shape[2]\n",
        "\n",
        "# # Print the dimensions\n",
        "# print(f\"Image width: {width} pixels\")\n",
        "# print(f\"Image height: {height} pixels\")\n",
        "# print(f\"Number of channels: {channels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1692bhvuvjF",
        "outputId": "a8f62f32-3373-4778-dd39-05caedd753a1"
      },
      "outputs": [],
      "source": [
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode = 'binary',\n",
        "    image_size=(224,224) ,\n",
        "    batch_size =32,\n",
        "    color_mode = 'rgb'\n",
        ")\n",
        "\n",
        "\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    label_mode = 'binary',\n",
        "    image_size=(224,224) ,\n",
        "    batch_size =32,\n",
        "    color_mode = 'rgb'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix_ZAvKau4on"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    preprocessing.RandomFlip(),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2)\n",
        "    # preprocessing.Rescale(1/255.),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wyOsUXu9dE",
        "outputId": "96d2de5b-d598-4402-9960-32e87a4a8dc1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "input_shape = (224,224,3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable  = False\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape = input_shape)\n",
        "\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x , training = False)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "outputs = layers.Dense(1 , activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "\n",
        "model_1 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "model_1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNfh-v-CvP_H"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "path = '/content/'\n",
        "model_ckpt= tf.keras.callbacks.ModelCheckpoint(filepath = path,\n",
        "                                               save_weight_only = True,\n",
        "                                               save_best_only = True,\n",
        "                                               save_freq = 'epoch',\n",
        "                                               verbose=1\n",
        "                                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9RptfEhvWMj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr6wd25QvRAX",
        "outputId": "8ec0f83c-12f5-4693-eb58-9e18d0a929b4"
      },
      "outputs": [],
      "source": [
        "model_1.compile(loss = 'binary_crossentropy', optimizer= tf.keras.optimizers.Adam(lr=1e-4) ,metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history_1 = model_1.fit(train_data ,\n",
        "                        epochs  = 30,\n",
        "                        steps_per_epoch= len(train_data),\n",
        "                        validation_data = test_data,\n",
        "                        validation_steps = int(0.15*len(test_data)),\n",
        "                        callbacks = [early_stopping_cb , model_ckpt]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR2tlFJX0rde",
        "outputId": "1ceadbce-33ba-4ad9-a033-e60a0483f9a4"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wsw1OwV74O5",
        "outputId": "b4ab46ed-4924-4b9f-83a5-fe749c986d6f"
      },
      "outputs": [],
      "source": [
        "custom_threshold = 0.6  # Example threshold value\n",
        "validation_data = test_data  # Replace with the actual validation dataset\n",
        "y_pred = model_1.predict(validation_data)\n",
        "y_pred_binary = (y_pred > custom_threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-3sWQ7Z-PIC"
      },
      "outputs": [],
      "source": [
        "label_mapping = {'A': 1, 'notA': 1}\n",
        "\n",
        "true_labels = [label_mapping[path.split('/')[-2]] for path in file_paths]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC6uohi88hHp",
        "outputId": "dd1af0fc-05ce-44b3-b643-3448279ff5f5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred_binary)\n",
        "precision = precision_score(true_labels, y_pred_binary)\n",
        "recall = recall_score(true_labels, y_pred_binary)\n",
        "f1 = f1_score(true_labels, y_pred_binary)\n",
        "conf_matrix = confusion_matrix(true_labels, y_pred_binary)\n",
        "\n",
        "# Print or use the evaluation results as needed\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZG5pJym_lKo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "J1AEm6cBojjq",
        "outputId": "d9393017-57de-4cf8-c30f-3ffaa2fdcdc4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier  # Correct import\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define a function to create the Keras model\n",
        "def create_model(learning_rate=0.001, num_units=256):\n",
        "    base_model = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False, weights='imagenet', input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(num_units, activation='relu')(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Specify the data directory\n",
        "train_data_dir = 'path_to_training_data'  # Replace with the actual path\n",
        "\n",
        "# Create an ImageDataGenerator to load and preprocess the images\n",
        "datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "X = train_generator  # Set X to the generator\n",
        "y = train_generator.classes  # Set y to the class labels\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'num_units': [128, 256, 512]\n",
        "}\n",
        "\n",
        "# Create a KerasClassifier\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "# Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Print the best hyperparameters and accuracy\n",
        "print(f'Best Parameters: {grid_result.best_params_}')\n",
        "print(f'Best Accuracy: {grid_result.best_score_}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Torch + Vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seeds(seed: int=42):\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 768])\n",
            "torch.Size([768, 3, 16, 16])\n",
            "torch.Size([768])\n",
            "torch.Size([1, 197, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([2304, 768])\n",
            "torch.Size([2304])\n",
            "torch.Size([768, 768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072, 768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768, 3072])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([1000, 768])\n",
            "torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "# 1. Get pretrained weights for ViT-Base\n",
        "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT \n",
        "\n",
        "# 2. Setup a ViT model instance with pretrained weights\n",
        "pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)\n",
        "\n",
        "# 3. Freeze the base parameters\n",
        "for parameter in pretrained_vit.parameters():\n",
        "    parameter.requires_grad = False\n",
        "    print(parameter.shape)\n",
        "    \n",
        "# 4. Change the classifier head \n",
        "class_names = ['A','Not_A']\n",
        "\n",
        "set_seeds()\n",
        "pretrained_vit.heads = nn.Linear(in_features=768, out_features=len(class_names)).to(device)\n",
        "# pretrained_vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "VisionTransformer (VisionTransformer)                        [64, 3, 224, 224]    [64, 2]              768                  Partial\n",
              "Conv2d (conv_proj)                                         [64, 3, 224, 224]    [64, 768, 14, 14]    (590,592)            False\n",
              "Encoder (encoder)                                          [64, 197, 768]       [64, 197, 768]       151,296              False\n",
              "    Dropout (dropout)                                     [64, 197, 768]       [64, 197, 768]       --                   --\n",
              "    Sequential (layers)                                   [64, 197, 768]       [64, 197, 768]       --                   False\n",
              "        EncoderBlock (encoder_layer_0)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_1)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_2)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_3)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_4)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_5)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_6)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_7)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_8)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_9)                   [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_10)                  [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "        EncoderBlock (encoder_layer_11)                  [64, 197, 768]       [64, 197, 768]       (7,087,872)          False\n",
              "    LayerNorm (ln)                                        [64, 197, 768]       [64, 197, 768]       (1,536)              False\n",
              "Linear (heads)                                             [64, 768]            [64, 2]              1,538                True\n",
              "============================================================================================================================================\n",
              "Total params: 85,800,194\n",
              "Trainable params: 1,538\n",
              "Non-trainable params: 85,798,656\n",
              "Total mult-adds (Units.GIGABYTES): 11.04\n",
              "============================================================================================================================================\n",
              "Input size (MB): 38.54\n",
              "Forward/backward pass size (MB): 6661.47\n",
              "Params size (MB): 229.20\n",
              "Estimated Total Size (MB): 6929.21\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# Print a summary using torchinfo (uncomment for actual output)\n",
        "summary(model=pretrained_vit, \n",
        "        input_size=(64, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup directory paths to train and test images\n",
        "train_dir = 'C:/Users/Machine Learning GPU/114/Balanced_dataset/balanced_train'\n",
        "test_dir = 'C:/Users/Machine Learning GPU/114/Balanced_dataset/balanced_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[256]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get automatic transforms from pretrained ViT weights\n",
        "pretrained_vit_transforms = pretrained_vit_weights.transforms()\n",
        "print(pretrained_vit_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str, \n",
        "    test_dir: str, \n",
        "    transform: transforms.Compose, \n",
        "    batch_size: int, \n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "    # Use ImageFolder to create dataset(s)\n",
        "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "    test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = train_data.classes\n",
        "\n",
        "    # Turn images into data loaders\n",
        "    train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup dataloaders\n",
        "train_dataloader_pretrained, test_dataloader_pretrained, class_names = create_dataloaders(train_dir=train_dir,\n",
        "                                                                                                     test_dir=test_dir,\n",
        "                                                                                                     transform=pretrained_vit_transforms,\n",
        "                                                                                                     batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def train_step(model: torch.nn.Module, \n",
        "               dataloader: torch.utils.data.DataLoader, \n",
        "               loss_fn: torch.nn.Module, \n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() \n",
        "\n",
        "        #Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        #Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        #Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module, \n",
        "              dataloader: torch.utils.data.DataLoader, \n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "    model.eval() \n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            \n",
        "            X, y = X.to(device), y.to(device)\n",
        "            test_pred_logits = model(X)\n",
        "            \n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module, \n",
        "          train_dataloader: torch.utils.data.DataLoader, \n",
        "          test_dataloader: torch.utils.data.DataLoader, \n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        dataloader=test_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25a2547c423a4722b1b082f7742a424b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.5929 | train_acc: 0.6870 | test_loss: 0.5696 | test_acc: 0.7103\n",
            "Epoch: 2 | train_loss: 0.5589 | train_acc: 0.7191 | test_loss: 0.5562 | test_acc: 0.7218\n",
            "Epoch: 3 | train_loss: 0.5496 | train_acc: 0.7258 | test_loss: 0.5505 | test_acc: 0.7268\n",
            "Epoch: 4 | train_loss: 0.5449 | train_acc: 0.7301 | test_loss: 0.5482 | test_acc: 0.7299\n",
            "Epoch: 5 | train_loss: 0.5415 | train_acc: 0.7326 | test_loss: 0.5454 | test_acc: 0.7314\n",
            "Epoch: 6 | train_loss: 0.5388 | train_acc: 0.7339 | test_loss: 0.5418 | test_acc: 0.7343\n",
            "Epoch: 7 | train_loss: 0.5369 | train_acc: 0.7360 | test_loss: 0.5405 | test_acc: 0.7355\n",
            "Epoch: 8 | train_loss: 0.5355 | train_acc: 0.7363 | test_loss: 0.5412 | test_acc: 0.7338\n",
            "Epoch: 9 | train_loss: 0.5340 | train_acc: 0.7386 | test_loss: 0.5382 | test_acc: 0.7372\n",
            "Epoch: 10 | train_loss: 0.5331 | train_acc: 0.7390 | test_loss: 0.5367 | test_acc: 0.7384\n",
            "Epoch: 11 | train_loss: 0.5314 | train_acc: 0.7391 | test_loss: 0.5365 | test_acc: 0.7384\n",
            "Epoch: 12 | train_loss: 0.5309 | train_acc: 0.7405 | test_loss: 0.5355 | test_acc: 0.7393\n",
            "Epoch: 13 | train_loss: 0.5303 | train_acc: 0.7403 | test_loss: 0.5352 | test_acc: 0.7401\n",
            "Epoch: 14 | train_loss: 0.5298 | train_acc: 0.7410 | test_loss: 0.5353 | test_acc: 0.7385\n",
            "Epoch: 15 | train_loss: 0.5295 | train_acc: 0.7408 | test_loss: 0.5343 | test_acc: 0.7388\n",
            "Epoch: 16 | train_loss: 0.5289 | train_acc: 0.7417 | test_loss: 0.5339 | test_acc: 0.7415\n",
            "Epoch: 17 | train_loss: 0.5285 | train_acc: 0.7418 | test_loss: 0.5335 | test_acc: 0.7407\n",
            "Epoch: 18 | train_loss: 0.5281 | train_acc: 0.7421 | test_loss: 0.5339 | test_acc: 0.7407\n",
            "Epoch: 19 | train_loss: 0.5278 | train_acc: 0.7429 | test_loss: 0.5334 | test_acc: 0.7406\n",
            "Epoch: 20 | train_loss: 0.5273 | train_acc: 0.7426 | test_loss: 0.5328 | test_acc: 0.7414\n",
            "Epoch: 21 | train_loss: 0.5266 | train_acc: 0.7435 | test_loss: 0.5324 | test_acc: 0.7419\n",
            "Epoch: 22 | train_loss: 0.5265 | train_acc: 0.7433 | test_loss: 0.5325 | test_acc: 0.7417\n",
            "Epoch: 23 | train_loss: 0.5265 | train_acc: 0.7431 | test_loss: 0.5321 | test_acc: 0.7415\n",
            "Epoch: 24 | train_loss: 0.5263 | train_acc: 0.7437 | test_loss: 0.5324 | test_acc: 0.7410\n",
            "Epoch: 25 | train_loss: 0.5259 | train_acc: 0.7439 | test_loss: 0.5322 | test_acc: 0.7410\n",
            "Epoch: 26 | train_loss: 0.5258 | train_acc: 0.7437 | test_loss: 0.5327 | test_acc: 0.7415\n",
            "Epoch: 27 | train_loss: 0.5257 | train_acc: 0.7436 | test_loss: 0.5317 | test_acc: 0.7418\n",
            "Epoch: 28 | train_loss: 0.5255 | train_acc: 0.7441 | test_loss: 0.5314 | test_acc: 0.7418\n",
            "Epoch: 29 | train_loss: 0.5254 | train_acc: 0.7439 | test_loss: 0.5313 | test_acc: 0.7424\n",
            "Epoch: 30 | train_loss: 0.5252 | train_acc: 0.7439 | test_loss: 0.5314 | test_acc: 0.7415\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "fine_tune_layers = pretrained_vit.heads.parameters()\n",
        "\n",
        "# Create optimizer and loss function\n",
        "optimizer = torch.optim.Adam(params=[{'params': fine_tune_layers}], lr=1e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# Train the classifier head of the pretrained ViT feature extractor model\n",
        "set_seeds()\n",
        "pretrained_vit_results = train(model=pretrained_vit,\n",
        "                                      train_dataloader=train_dataloader_pretrained,\n",
        "                                      test_dataloader=test_dataloader_pretrained,\n",
        "                                      optimizer=optimizer,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      epochs=30,\n",
        "                                      device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veELtipAojg6"
      },
      "outputs": [],
      "source": [
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
